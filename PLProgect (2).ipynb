{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "288718ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, time, os, tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.keras.utils.data_utils import get_file\n",
    "import matplotlib.pyplot as plt\n",
    "from cvlib.object_detection import draw_bbox\n",
    "\n",
    "import cvlib as cv\n",
    "\n",
    "np.random.seed(20)\n",
    "\n",
    "class Detector:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def readClasses(self, classesFilePath):\n",
    "        with open(classesFilePath, 'r') as f:\n",
    "            self.classesList = f.read().splitlines()\n",
    "            self.colorList = np.random.uniform(low = 0,high =255, size = (len(self.classesList),3))\n",
    "            print(len(self.classesList),len(self.colorList))\n",
    "\n",
    "    def downloadModel(self, modelURL):\n",
    "        fileName = os.path.basename(modelURL)\n",
    "        self.modelName = fileName[:fileName.index('.')]\n",
    "        print(fileName)\n",
    "        print(self.modelName)\n",
    "        self.cacheDir = \"./pretrained_models\"    \n",
    "        os.makedirs(self.cacheDir, exist_ok = True)\n",
    "        get_file(fname = fileName, origin=modelURL,cache_dir=self.cacheDir,cache_subdir=\"checkpoints\",extract = True)\n",
    "        \n",
    "    def loadModel(self):\n",
    "        print(\"Loading Model\" + self.modelName)\n",
    "        tf.keras.backend.clear_session()\n",
    "        self.model = tf.saved_model.load(os.path.join(self.cacheDir,\"checkpoints\",self.modelName,\"saved_model\"))\n",
    "        print(\"\\n\")\n",
    "        print(\"Model \" + self.modelName + \" loaded successfully!!\")\n",
    "        \n",
    "    def createBoundingbox(self,image, threshold = 0.5):\n",
    "        inputTensor = cv2.cvtColor(image.copy(),cv2.COLOR_BGR2RGB)\n",
    "        inputTensor = tf.convert_to_tensor(inputTensor,dtype = tf.uint8)\n",
    "        inputTensor = inputTensor[tf.newaxis,...]\n",
    "        detection = self.model(inputTensor)\n",
    "        bboxs = detection['detection_boxes'][0].numpy()\n",
    "        classIndexes = detection['detection_classes'][0].numpy().astype(np.int32)\n",
    "        classScores = detection['detection_scores'][0].numpy()\n",
    "        imH, imW, imC = image.shape\n",
    "        bboxIdx = tf.image.non_max_suppression(bboxs, classScores, max_output_size = 50,iou_threshold=threshold,score_threshold=threshold)\n",
    "        if len(bboxIdx) != 0:\n",
    "            for i in bboxIdx:\n",
    "                bbox = tuple(bboxs[i])\n",
    "                classConfidence = np.round(100*classScores[i])\n",
    "                classIndex = classIndexes[i]\n",
    "                classLabelText = self.classesList[classIndex].upper()\n",
    "                classColor = self.colorList[classIndex]\n",
    "                displayText = '{}: {}%'.format(classLabelText,classConfidence)\n",
    "                ymin, xmin, ymax, xmax = bbox\n",
    "                xmin, xmax, ymin, ymax = (xmin*imW , xmax*imW, ymin*imH, ymax*imH)\n",
    "                xmin, xmax, ymin, ymax = int(xmin),int(xmax), int(ymin),int(ymax)\n",
    "                cv2.rectangle(image, (xmin,ymin),(xmax,ymax),color = classColor,thickness = 1)\n",
    "                cv2.putText(image, displayText,(xmin , ymin - 10), cv2.FONT_HERSHEY_PLAIN, 1, classColor,2)\n",
    "                lineWidth = min(int((xmax - xmin)*0.2), int((ymax - ymin)*0.2))\n",
    "                cv2.line(image,(xmin,ymin),(xmin+lineWidth,ymin),classColor,thickness = 5)\n",
    "                cv2.line(image,(xmin,ymin),(xmin,ymin+lineWidth),classColor,thickness = 5)\n",
    "                cv2.line(image,(xmax,ymin),(xmax-lineWidth,ymin),classColor,thickness = 5)\n",
    "                cv2.line(image,(xmax,ymin),(xmax,ymin+lineWidth),classColor,thickness = 5)\n",
    "                #########\n",
    "                cv2.line(image,(xmin,ymax),(xmin+lineWidth,ymax),classColor,thickness = 5)\n",
    "                cv2.line(image,(xmin,ymax),(xmin,ymax-lineWidth),classColor,thickness = 5)\n",
    "                cv2.line(image,(xmax,ymax),(xmax-lineWidth,ymax),classColor,thickness = 5)\n",
    "                cv2.line(image,(xmax,ymax),(xmax,ymin-lineWidth),classColor,thickness = 5)\n",
    "        return image      \n",
    "                \n",
    "        \n",
    "        \n",
    "    def predictImage(self, imagePath,threshold = 0.5):\n",
    "        image = cv2.imread(imagePath)\n",
    "        bboxImage = self.createBoundingbox(image,threshold)\n",
    "        cv2.imwrite(self.modelName + \".jpeg\",bboxImage)\n",
    "        cv2.imshow(\"Result\",bboxImage)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "    def predictVideo(self,videoPath, threshold = 0.5):\n",
    "        cap = cv2.VideoCapture(videoPath)\n",
    "        if(cap.isOpened() == False):\n",
    "            print(\"Error opening file .......\")\n",
    "            return\n",
    "        (success, image) = cap.read()\n",
    "        startTime = 0\n",
    "        while success:\n",
    "            labels = []\n",
    "            currentTime = time.time()\n",
    "            fps = 1/(currentTime - startTime)\n",
    "            startTime = currentTime\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            # Detect objects and draw on screen\n",
    "            bbox, label, conf = cv.detect_common_objects(frame)\n",
    "            \n",
    "            bboxImage = self.createBoundingbox(frame,threshold)\n",
    "            cv2.putText(bboxImage,\"FPS : \"+str(int(fps)),(20,70),cv2.FONT_HERSHEY_PLAIN,2,(0,255,0),2)\n",
    "            cv2.imshow(\"Result\",bboxImage)\n",
    "            for item in label:\n",
    "                if item in labels:\n",
    "                    break\n",
    "                else:\n",
    "                    labels.append(item)\n",
    "            print(labels)\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord(\"q\"):\n",
    "                break\n",
    "            (success,image) = cap.read()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffda17c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelURL = \"http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz\"\n",
    "\n",
    "classFile = \"C:/Users/perep/OneDrive/Desktop/spring 2023/programming lamguages/project/project2/coco.names\"\n",
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d96a385",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5871e067",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePth = \"C:/Users/perep/OneDrive/Desktop/spring 2023/programming lamguages/project/project2/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "556eb429",
   "metadata": {},
   "outputs": [],
   "source": [
    "videoPth =\"C:/Users/perep/OneDrive/Desktop/spring 2023/programming lamguages/project/project2/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d60e9150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92 92\n",
      "ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz\n",
      "ssd_mobilenet_v2_320x320_coco17_tpu-8\n",
      "Loading Modelssd_mobilenet_v2_320x320_coco17_tpu-8\n",
      "\n",
      "\n",
      "Model ssd_mobilenet_v2_320x320_coco17_tpu-8 loaded successfully!!\n"
     ]
    }
   ],
   "source": [
    "detect = Detector()\n",
    "detect.readClasses(classFile)\n",
    "detect.downloadModel(modelURL)\n",
    "detect.loadModel()\n",
    "\n",
    "#detect.predictVideo(videoPath,threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cac86e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.enter your selection for object detection\n",
      "1. Image\n",
      "2. Video\n",
      " 3. Camera\n",
      "\n",
      "enter your choice: 3\n",
      "['person']\n",
      "['person']\n",
      "['person']\n",
      "['person']\n",
      "['person']\n",
      "['person']\n",
      "['person']\n",
      "['person']\n",
      "['person']\n",
      "['person']\n",
      "[]\n",
      "['person']\n",
      "[]\n",
      "['dog']\n",
      "['person']\n",
      "[]\n",
      "[]\n",
      "['person']\n",
      "[]\n",
      "[]\n",
      "['cow']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "['cow']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "['person']\n",
      "[]\n",
      "['tv']\n",
      "['tv']\n",
      "['person', 'tv']\n",
      "['tv', 'person']\n",
      "['tv', 'person']\n",
      "['tv', 'person']\n",
      "['tv', 'person']\n",
      "['tv', 'person']\n",
      "['person', 'tv']\n",
      "['tv', 'person']\n",
      "['tv', 'person']\n",
      "['microwave', 'person']\n",
      "[]\n",
      "['bed']\n",
      "['bed']\n",
      "['bed']\n",
      "['bed']\n",
      "[]\n",
      "['person']\n",
      "['person']\n",
      "['person']\n",
      "['person']\n",
      "['person']\n",
      "['person']\n",
      "['person']\n",
      "['person']\n",
      "['person']\n",
      "['person']\n",
      "['person']\n",
      "['person']\n",
      "['person']\n",
      "['person']\n",
      "If you want to continue please enter y, else please enter nn\n",
      "Thank you !!!\n"
     ]
    }
   ],
   "source": [
    "choice = \"y\"\n",
    "while (choice == \"y\"):\n",
    "    print(\"1.enter your selection for object detection\")\n",
    "    print(\"1. Image\\n2. Video\\n 3. Camera\\n\")\n",
    "    n = int(input(\"enter your choice: \"))\n",
    "    if(n == 1):\n",
    "        path = input(\"enter your image name with extension : \")\n",
    "        ImagePath = imagePth + path\n",
    "        print(ImagePath)\n",
    "        detect.predictImage(ImagePath,threshold)\n",
    "    elif(n == 2):\n",
    "        path = input(\"enter your video name with extension : \")\n",
    "        VideoPath = videoPth + path\n",
    "        detect.predictVideo(VideoPath,threshold)\n",
    "    elif(n == 3):\n",
    "        detect.predictVideo(0,threshold)\n",
    "    else:\n",
    "        print(\"Sorry,you have entered the wrong number!\")\n",
    "    choice = input(\"If you want to continue please enter y, else please enter n\")\n",
    "print(\"Thank you !!!\")   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fa3493",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
